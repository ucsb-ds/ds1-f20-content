{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab08: Classification Continued\n",
    "Welcome to lab08. We will be continuing our discussion of classification with K-Nearest Neighbors as well as Nearest Neighbors in more than 2 dimensions.\n",
    "\n",
    "\n",
    "Relevant chapters from the textbook are:\n",
    "* [Chapter 7](https://www.inferentialthinking.com/chapters/07/Visualization.html)\n",
    "* [Chapter 8](https://www.inferentialthinking.com/chapters/08/Functions_and_Tables.html)\n",
    "* [Chapter 17](https://www.inferentialthinking.com/chapters/17/Classification.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "#from NearestNeighbors import *\n",
    "import random \n",
    "# These lines set up graphing capabilities.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "np.random.seed(3)\n",
    "random.seed(3)\n",
    "\n",
    "\n",
    "# Ignore these Functions\n",
    "def standard_units(x):\n",
    "    return (x - np.mean(x))/np.std(x)\n",
    "\n",
    "def make_grid(min_, max_, step):\n",
    "    x_array = make_array()\n",
    "    y_array = make_array()\n",
    "    for x in np.arange(min_, max_, step):\n",
    "        for y in np.arange(min_, max_, step):\n",
    "            x_array = np.append(x_array, x)\n",
    "            y_array = np.append(y_array, y)\n",
    "    return x_array, y_array\n",
    "\n",
    "def distance_nn(point1, point2):\n",
    "    \"\"\"The distance between two arrays of numbers.\"\"\"\n",
    "    return np.sqrt(np.sum((point1 - point2)**2))\n",
    "\n",
    "def all_distances(training, point):\n",
    "    \"\"\"The distance between p (an array of numbers) and the numbers in row i of attribute_table.\"\"\"\n",
    "    attributes = training.drop('Class')\n",
    "    def distance_from_point(row):\n",
    "        return distance_nn(point, np.array(row))\n",
    "    return attributes.apply(distance_from_point)\n",
    "\n",
    "def table_with_distances(training, point):\n",
    "    \"\"\"A copy of the training table with the distance from each row to array p.\"\"\"\n",
    "    return training.with_column('Distance', all_distances(training, point))\n",
    "\n",
    "def closest(training, point, k):\n",
    "    \"\"\"A table containing the k closest rows in the training table to array p.\"\"\"\n",
    "    with_dists = table_with_distances(training, point)\n",
    "    sorted_by_distance = with_dists.sort('Distance')\n",
    "    topk = sorted_by_distance.take(np.arange(k))\n",
    "    return topk\n",
    "\n",
    "def majority(topkclasses):\n",
    "    \"\"\"1 if the majority of the \"Class\" column is 1s, and 0 otherwise.\"\"\"\n",
    "    ones = topkclasses.where('Class', are.equal_to(1)).num_rows\n",
    "    zeros = topkclasses.where('Class', are.equal_to(0)).num_rows\n",
    "    if ones > zeros:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def classify(training, p, k):\n",
    "    \"\"\"Classify an example with attributes p using k-nearest neighbor classification with the given training table.\"\"\"\n",
    "    closestk = closest(training, p, k)\n",
    "    topkclasses = closestk.select('Class')\n",
    "    return majority(topkclasses)\n",
    "\n",
    "def classify_table(training, points, k):\n",
    "    \"\"\"Classify a table of unlabled points using KNN\"\"\"\n",
    "    def classify_p(p):\n",
    "        return classify(training, p, k)\n",
    "\n",
    "    classes = points.apply(classify_p)\n",
    "    return points.with_column('Class', classes)\n",
    "\n",
    "def draw_nearest_neighbor(table, point):\n",
    "    with_distances = table_with_distances(table, point)\n",
    "    distances_sorted = with_distances.sort('Distance', descending=False)\n",
    "\n",
    "    t = distances_sorted.drop('Distance')\n",
    "\n",
    "    x_closest = t.row(0).item(0)\n",
    "    y_closest = t.row(0).item(1)\n",
    "\n",
    "    table.scatter(table.labels[0], table.labels[1], group='Class')\n",
    "    plt.scatter(point.item(0), point.item(1), color='red', s=30)\n",
    "    plt.plot(make_array(point.item(0), x_closest), make_array(point.item(1), y_closest), color='k', lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 0. 3D distance\n",
    "In lab section:\n",
    "1. Derive the formula for 3d distance. \n",
    "2. Give the formula (without proof) for N-d distance.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0\n",
    "manual: false\n",
    "-->\n",
    "For submission:\n",
    "\n",
    "**q0** What is the distance between the points $P_1=(1,1,1)$ and $P_2 = (4, 5, 13)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lobsters\n",
    "We are going to take another look at the lobster dataset. Recall that this meticulously handcrafted dataset contains information about claw width, tail lenght and the sex of lobsters. A value of zero in the 'Class' column denotes a female and a value of one denotes a male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobster = Table.read_table('lobster.csv')\n",
    "lobster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobster.scatter('Claw Width', 'Tail Length', group='Class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Visualizing the Lobster Decision Boundary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like last week, we are going to visualize the decision boundary produced by the Nearest Neighbors algorithm. This time, we have given you the code that generates these plots. The first step is to make a grid that contains points that fills the space.\n",
    "\n",
    "Below, we make a table that contains such a grid using the `make_grid` function, which we have implemented for you. The  blue and yellow points are from the original dataset and the red points make up the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array, y_array = make_grid(4, 20, .5)\n",
    "test_grid = Table().with_columns(\n",
    "    'Claw Width', x_array,\n",
    "    'Tail Length', y_array\n",
    ")\n",
    "test_grid.scatter('Claw Width', 'Tail Length', color='red', alpha=0.4, s=30)\n",
    "\n",
    "\n",
    "plt.scatter(lobster.column('Claw Width',), lobster.column('Tail Length'), c=lobster.column('Class'), edgecolor='k')\n",
    "\n",
    "plt.xlim(4, 20)\n",
    "plt.ylim(4, 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we classify every point in the grid. We have implemented for you a function called `classify_table`, which labels every single point in an unlabled grid. Under the hood, this calls Nearest Neighbors on each row using `apply`. \n",
    "\n",
    "This may take a while because there are a lot of points to classify. (If you see the '*' in the brackets to the left of the cell, the code is still running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_grid = classify_table(lobster, test_grid, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_grid.scatter('Claw Width', 'Tail Length', group='Class', alpha=0.4, s=30)\n",
    "\n",
    "plt.scatter(lobster.column('Claw Width'), lobster.column('Tail Length'), c=lobster.column('Class'), edgecolor='k')\n",
    "\n",
    "plt.xlim(4,20)\n",
    "plt.ylim(4,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 A Problem with Nearest Neighbor Search\n",
    "The regions above identifying female and male lobsters are not cleanly separated. Let's investigate what is causing the issue by looking at a single point: (17,5)\n",
    "\n",
    "We have given you a function called `draw_nearest_neighbor` that takes in an arbitrary table and an arbitrary point and plots the points in the table, the point, and a line between the point (in red) and the closest point to it in the table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_nearest_neighbor(lobster, make_array(17,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arguably want to see the region of male class '1' lobsters be a solid diagonal stripe. It would also be nice if the regions of female class '0' lobsters made solid triangles on either side of the stripe. However, because some male lobsters cross into the region of female lobsters, and because our classified data points are relatively sparse, some points well within the expected region of the female lobsters have as their nearest neighbor a male lobster.\n",
    "\n",
    "We can see this occured witht the point (17, 5). You may notice, that the next several closest neighbors of that point are all female. This suggests that we can generate a better decision boundary by looking at the labels of a few closest neighbors instead of just one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K Nearest Neighbors\n",
    "K Nearest Neighbors is a classification algorithm that classifies a point based on whatever the majority of the point's k nearest-neighbors are labeled, where k is an arbitrary integer. \n",
    "\n",
    "## 2.1 Implementing K Nearest Neighbors\n",
    "The implementation of the K Nearest Neighbors algorithm is very similar to the regular Nearest neighbors algorithm.\n",
    "\n",
    "1. We find the distance between the unlableled point and every point in our table. \n",
    "2. We sort the table by distances. \n",
    "3. Instead of taking the row with the smallest distance, we will look at the top-k rows with the smallest distances.\n",
    "4. We find the majority class of those rows\n",
    "\n",
    "We have implemented steps #1 and #2 for you because we did those steps in lab07. The function `table_with_distances` takes in a table with 3 columns, one of which is called 'Class', and a point and returns a new table with an additional column called 'Distances' which has the distance between each row and the given point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "points: 1\n",
    "manual: false\n",
    "-->\n",
    "\n",
    "**q2.1** We will now implement step #3. Write a function called `closest` that takes in a labeled table, a point, and a value k and returns the top-k closest points. \n",
    "\n",
    "you may use`table_with_distances`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(input_table, point, k):\n",
    "    # Recommended code structure\n",
    "    distance_table = ...\n",
    "    sorted_table_with_distances = ...\n",
    "    topk = ...\n",
    "    return topk\n",
    "    \n",
    "\n",
    "# To check your solution:\n",
    "kclosest = closest(lobster, make_array(12.55,18.6), 4)\n",
    "kclosest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.2 Finding the Majority\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_2\n",
    "points: 1\n",
    "manual: false\n",
    "-->\n",
    "The last step is to find the majority label from the table of k-closet neighbors.\n",
    "\n",
    "**q2.2** Write a function called `majority` that takes in a table with a 'Class' column that has values of either 0 or 1.  The function should return the class that occurs with the highest frequency.\n",
    "\n",
    "To do this, you will first need to find the number of times each label occurs. Then you will have to use an if statement to return the correct label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(table):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_label = majority(kclosest)\n",
    "majority_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2.3 K-Nearest Neighbors Function\n",
    "**q2.3** Now that we have implemented all of the components, we can stitch them together to create a `classify-knn` function. `classify-knn` should take in a table, a point, and a number k, and return the class assigned to the majority of the k-clsoest neighbors of the point.\n",
    "\n",
    "If you use `closest` and `majority` correctly, your code should be fairly short.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_3\n",
    "points: 1\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_knn(input_table, point, k):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have implemented for you a more general function that can classify an entire table of unlabled points. This function requires your `classify_knn` function to work correctly.\n",
    "\n",
    "Marvel at the fact that you define functions inside functions, but not for too long. This is necessary because we have to make a new `classify_knn` function for every unlabeled point if we want to use it with `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfiy_table_knn(labeled_table, unlabeled_table, k):\n",
    "    \n",
    "    def classify_point_by_table_k(unlabeled_point):\n",
    "        return classify_knn(labeled_table, unlabeled_point, k)\n",
    "    \n",
    "    labels = unlabeled_table.apply(classify_point_by_table_k)\n",
    "    table_with_labels = unlabeled_table.with_column('Class', labels)\n",
    "    \n",
    "    return table_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 KNN Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that can classify an entire table using KNN, let's look at the new decision boundary looks like. We will run the same grid-classification experiments as before, but we will now classify all points using K Nearest Neighbors with an aribitrarily chosen value of k=5.\n",
    "\n",
    "Again, the first cell may take a while to run because there are a lot of points in the grid to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array, y_array = make_grid(4, 20, .5)\n",
    "test_grid = Table().with_columns(\n",
    "    'Claw Width', x_array,\n",
    "    'Tail Length', y_array\n",
    ")\n",
    "k=5\n",
    "labeled_grid = classfiy_table_knn(lobster, test_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_grid.scatter('Claw Width', 'Tail Length', group='Class', alpha=0.4, s=30)\n",
    "\n",
    "plt.scatter(lobster.column('Claw Width'), lobster.column('Tail Length'), c=lobster.column('Class'), edgecolor='k')\n",
    "\n",
    "plt.xlim(4,22)\n",
    "plt.ylim(4,22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_4\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "Compare the decision boundary of the table above with the decision boundary displayed in section 2.1. Which do you prefer and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# 2.5 Brain Teasers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Two more brain teasers about K Nearest Neighbors\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_5_1\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "**q2.5.1** In general, datascientists choose k to be odd. Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_5_2\n",
    "points: 1\n",
    "manual: false\n",
    "-->\n",
    "**q2.5.2** What value of k makes K-Nearest Neighbors equivalent to vanilla Nearest Neighbor Search as we impleneted in lab07?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 Evaluating Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate the accuracy by comparing the predictions of our algorithm on the testing set against their actual labels. \n",
    "\n",
    "The code below splits the data into a training and testing set and creates an array that represents the *predicted* class of each point in the test dataset using Nearest Neighbors. We visualized the decision boundary of the training this training set with k=1 in lab07 section 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = lobster.take(np.arange(160))\n",
    "testing = lobster.take(np.arange(160, 200))\n",
    "\n",
    "test_predictions = classify_table(training, testing.drop('Class'), 1).column('Class')\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The **accuracy** of a model is defined as \n",
    "$$\\frac{\\text{Correct Predictions}}{\\text{Total Predictions}}$$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_6\n",
    "manual: false\n",
    "-->\n",
    "\n",
    "**q2.6** What is the accuracy of the Nearest Neighbors Classifier on the *test* data?\n",
    "\n",
    "There are a few ways you could solve this problem. One way is to:\n",
    "1. Make an array of the actual classes of the dataset by getting the 'Class' column of `testing`.\n",
    "2. Take the difference between the predicted and actual labels by subtracting the two arrays.\n",
    "3. Use the result of that array and the function np.count_nonzero() to find the number of points classified incorrectly.\n",
    "4. Use step (3) to calculate the number of points calculated correctly.\n",
    "5. Divide by the total number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested code structure\n",
    "true_classes = ...\n",
    "diff = ...\n",
    "num_incorrect = ...\n",
    "num_correct = ...\n",
    "accuracy = ...\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 More Than Two Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to look at a new task, predicting whether or not a dollar bill is fraudulent. To do this, we will use the `banknote` dataset. Each row in `banknote` gives information about an image of a bill. This information includes four features that were computed by researches using methods we do not need to understand. The fifth 'Class' column tells us whether the the bill is counterfit (one) or real (zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes = Table.read_table('banknote.csv')\n",
    "banknotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the first two columns and see what these features tell us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes.scatter('WaveletVar', 'WaveletCurt', group='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features distinguish the two classes to an extent, but there is still a significant region of overlap on which these features are not enough for classification. \n",
    "\n",
    "Make scatter plots with other columns to see if other pairs of features are more decisive. Feel free to add more cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT\n",
    "# banknotes.scatter(..., ..., group='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that new two features are quite enough. So let's try three features instead. The code below makes a 3D scatter plot based off of 'WaveletSkew', 'WaveletVar' and 'WaveletCurt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\n",
    "ax.scatter(banknotes.column('WaveletSkew'), \n",
    "           banknotes.column('WaveletVar'), \n",
    "           banknotes.column('WaveletCurt'), \n",
    "           c=banknotes.column('Class'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By selecting three features to plot, we have found a much more decisive boundary between the two classes. The clear clustering of each class should make it apparent that we can use K-Nearest Neighbors on this dataset. We will use the same setup as before. Note that of all the code we have written so far, the only piece that needs changing is the distance function we wrote at the beggining of lab 7.  \n",
    "\n",
    "Recall from section 0 of this lab, that the distance function can be written for an arbitrary number of dimensions. This is how we implemented the distance function in `classify_table`. So we don't actually need to change anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 3.1 Training and Testing\n",
    "Before we do anything, we need to split our data into training and testing datasets. We have to be careful, because unlike the `lobster` dataset, `banknotes` is not shuffled. If we select the first 100 rows for the trainig set, all rows will have the same class. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_1a\n",
    "points: 1\n",
    "manual: false\n",
    "-->\n",
    "**q3.1a** Make a shuffled version of `banknotes`. Then make the training set be the first 50 rows of that table and make the test set be the next 30 rows. We will use the Table function `sample` that will allow us to randomly select rows with replacement. To make sure that you read these instructions, here's the code that you need to assign to shuffled_banknotes: `banknotes.sample(with_replacement=False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_banknotes = ...\n",
    "banknotes_training = ...\n",
    "banknotes_testing = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_1b\n",
    "points: 3\n",
    "manual: false\n",
    "-->\n",
    "**q3.1b** Write a function called `accuracy` that returns the accuracy of a model given an array of the models predictions and an array of the true labels. You may want to refer back to question 2.6. (This time we are giving you the array of predictions as a parameter, so the code structre is a little simpler.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    # Suggested code structure\n",
    "    diff = ...\n",
    "    num_incorrect = ...\n",
    "    num_correct = ...\n",
    "    accuracy = ...\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Comparing Different Values of K\n",
    "Finally, let's use our `accuracy` function to evaluate different sizes of the neighboorhhood for evaluation in KNN. First, run the code following code which gives the arrays of predictions for each value of k stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = classify_table(banknotes_training, banknotes_testing.drop('Class'), 1).column('Class')\n",
    "predictions_3 = classify_table(banknotes_training, banknotes_testing.drop('Class'), 3).column('Class')\n",
    "predictions_5 = classify_table(banknotes_training, banknotes_testing.drop('Class'), 5).column('Class')\n",
    "predictions_7 = classify_table(banknotes_training, banknotes_testing.drop('Class'), 7).column('Class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**q3.2** Now find the accuracy of each models' predictions using your `accuracy` function.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_2\n",
    "points: 3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1 = \n",
    "accuracy_3 = \n",
    "accuracy_5 = \n",
    "accuracy_7 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**q3.3** Explain the trends you see in accuracy as $k$ increases. Do you see anything that you did not expect? What do you think might explain what you are seeing?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_3\n",
    "points: 3\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Congratulations, you are finished with this lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(\"lab08.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
